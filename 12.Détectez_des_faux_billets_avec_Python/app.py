
import streamlit as st
import pandas as pd
import joblib

st.set_page_config(page_title="DÃ©tection de faux billets", layout="wide")
st.title("ğŸ’¶ DÃ©tection automatique de faux billets")

# --- Chargement du pipeline ---
pipeline = joblib.load('models/pipeline.joblib')
reg_robustscaled = pipeline['nan_predict']
robust_scaler = pipeline['nan_scaler']
clf_standard = pipeline['model']
log_standard_scaler = pipeline['log_scaler']
best_threshold = pipeline['best_threshold']
features = pipeline.get('features', ['diagonal','length','height_left','height_right','margin_low','margin_up'])
impute_features = pipeline.get('impute_features', ['length','margin_up','height_right','height_left'])

# --- Upload CSV ---
uploaded_file = st.file_uploader("Importez votre fichier CSV", type=["csv"])

if uploaded_file is not None:
    # DÃ©tection automatique du sÃ©parateur
    df = pd.read_csv(uploaded_file, sep=None, engine='python')
    st.subheader("AperÃ§u des donnÃ©es")
    st.dataframe(df.head())

    # --- VÃ©rification des colonnes ---
    missing_cols = set(features + impute_features) - set(df.columns)
    if missing_cols:
        st.error(f"âŒ Colonnes manquantes dans le fichier : {missing_cols}")
    else:
        # --- Imputation pour margin_low ---
        if df['margin_low'].isna().any():
            df_nan = df.loc[df['margin_low'].isna()]
            predict_var = df_nan[['length', 'margin_up', 'height_right', 'height_left']]

            # Remplir temporairement les NaN restantes avec 0 pour Ã©viter ValueError
            predict_var_filled = predict_var.fillna(0)

            predict_var_scaled = pd.DataFrame(
                robust_scaler.transform(predict_var_filled),
                columns=predict_var.columns,
                index=predict_var.index
            )
            predict_nan = reg_robustscaled.predict(predict_var_scaled)
            df.loc[df['margin_low'].isna(), 'margin_low'] = predict_nan

        # --- VÃ©rification d'autres valeurs manquantes ---
        nan_cols = df[clf_standard.feature_names_in_].columns[df[clf_standard.feature_names_in_].isna().any()].tolist()
        if nan_cols:
            st.warning(f"âš ï¸ Attention, prÃ©sence de valeurs manquantes dans : {nan_cols}")
        else:
            st.success("âœ… Aucune valeur manquante dÃ©tectÃ©e")

        # --- Suppression des doublons ---
        df = df.drop_duplicates()

        # --- PrÃ©paration des donnÃ©es pour la prÃ©diction ---
        X = df[clf_standard.feature_names_in_].copy()

        # Identifier les lignes complÃ¨tes pour la prÃ©diction
        complete_rows = X.dropna().index
        X_complete = X.loc[complete_rows]

        # Scaler et prÃ©diction uniquement sur lignes complÃ¨tes
        X_scaled = pd.DataFrame(
            log_standard_scaler.transform(X_complete),
            columns=clf_standard.feature_names_in_,
            index=X_complete.index
        )
        pred = clf_standard.predict(X_scaled)
        proba = clf_standard.predict_proba(X_scaled)[:, 1]
        pred_opt = (proba >= best_threshold).astype(int)

        # Ajouter les rÃ©sultats dans df, NaN pour les lignes incomplÃ¨tes
        df['prediction'] = pd.NA
        df['probabilities'] = pd.NA
        df.loc[complete_rows, 'prediction'] = [True if p == 1 else False for p in pred_opt]
        df.loc[complete_rows, 'probabilities'] = proba

        # --- Comptage rÃ©sultats ---
        n_true = df['prediction'].sum(skipna=True)
        n_false = df['prediction'].count() - n_true
        n_true_pct = (n_true / df['prediction'].count() * 100).round(1)
        n_false_pct = (n_false / df['prediction'].count() * 100).round(1)
        # Liste des vrais et des faux billets
        true_bill = df.loc[df['prediction'] == True, 'id'].tolist()
        false_bill = df.loc[df['prediction'] == False, 'id'].tolist()

        # --- Billets incertains (Â±10% du seuil) ---
        threshold_pct = 10
        low_threshold = best_threshold * (1 - threshold_pct / 100)
        high_threshold = best_threshold * (1 + threshold_pct / 100)
        uncertain = df.loc[
            df['probabilities'].between(low_threshold, high_threshold),
            'id'
        ].dropna().tolist()
        n_uncertain = len(uncertain)
        pct_uncertain = round(n_uncertain / df['prediction'].count() * 100, 1)

        # --- Affichage des rÃ©sultats ---
        st.subheader("ğŸ“Š RÃ©sultats globaux")
        st.write(f"âœ… Billets vrais : {n_true} ({n_true_pct}%)")
        st.write(f"{true_bill}")
        st.write(f"âŒ Billets faux : {n_false} ({n_false_pct}%)")
        st.write(f"{false_bill}")
        st.write(f"ğŸ‘€ Billets Ã  vÃ©rifier : {n_uncertain} ({pct_uncertain}%)")
        if n_uncertain > 0:
            st.dataframe(pd.DataFrame({'id_suspects': uncertain}))

            # --- Optionnel : tÃ©lÃ©charger les billets suspects ---
            csv = pd.DataFrame({'id_suspects': uncertain}).to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ TÃ©lÃ©charger les billets suspects",
                data=csv,
                file_name='billets_suspects.csv',
                mime='text/csv'
            )
